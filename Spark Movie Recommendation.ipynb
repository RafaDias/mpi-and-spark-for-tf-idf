{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00726934",
   "metadata": {},
   "source": [
    "# Spark Movie Recommendation\n",
    "\n",
    "Disciplina de programação paralela CEFET-RJ  \n",
    "\n",
    "Discentes: Nadinne Guimarães Holanda e Rafael Assis Mello Pereira Dias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5add1c",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f429efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from enum import Enum\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8544071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import itertools\n",
    "from notebooks.data import text_mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3d7258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local[*]\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d65df",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "See more in: https://www.kaggle.com/shivamb/netflix-shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdb6cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./notebooks/data/netflix_titles.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7d7c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = df.select(\"description\").rdd.flatMap(lambda x: x).collect()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dec3d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5e796",
   "metadata": {},
   "source": [
    "## Functions to clean text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82962791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenize(text):\n",
    "    if not text:\n",
    "        print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "        text = ''\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b24e1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_cleaning(text):\n",
    "    tokens = custom_tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77ca1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(descriptions).map(lambda x: pipeline_cleaning(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b7276",
   "metadata": {},
   "source": [
    "## Computing time for pipeline cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68823295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.23 ms, sys: 7.75 ms, total: 17 ms\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_documents = rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42db7bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2d958dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(list(itertools.chain.from_iterable(tokenized_documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76adb7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5754"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42af3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = text_mining.calculate_df(vocab=vocab, corpus=tokenized_documents)\n",
    "IDF = text_mining.calculate_idf(VOCAB=vocab, DF=DF, corpus_size=len(tokenized_documents))\n",
    "TF = text_mining.calculate_tf(corpus=tokenized_documents, VOCAB=vocab)\n",
    "TF_IDF = text_mining.calculate_tf_idf(TF=TF, IDF=IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55f4be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for key in TF_IDF:\n",
    "    vectors.append(np.array(list(TF_IDF[key].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f44c8725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5c2d212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "index = random.randint(0, 1000)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49d31433",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = vectors.pop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7fcd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "choosed_movie = df.collect()[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7a33c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_items(n=1, similarity=None):\n",
    "    return sorted(similarity, key=lambda x: x[0], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f871544",
   "metadata": {},
   "source": [
    "## Computing time for cosine similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a50c91a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 ms, sys: 67.7 ms, total: 96.3 ms\n",
      "Wall time: 673 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rdd = sc.parallelize(vectors).map(lambda vector: text_mining.calc_cosine_similarity([movie], [vector]))\n",
    "similarity = rdd.zipWithIndex().collect()\n",
    "items = get_similarity_items(n=3, similarity=similarity)\n",
    "movie_items_index = [item[1] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e8ed0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a movie: American Experience: Ruby Ridge\n"
     ]
    }
   ],
   "source": [
    "print(f\"Given a movie: {choosed_movie['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42ed4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Movie and Tv Shows you may also like\"]\n",
    "\n",
    "for index in movie_items_index:\n",
    "    m = df.collect()[index]\n",
    "    x.add_row([m[\"title\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b7ec48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+\n",
      "| Movie and Tv Shows you may also like |\n",
      "+--------------------------------------+\n",
      "|             Arctic Heart             |\n",
      "|            Aagey Se Right            |\n",
      "|                6 Days                |\n",
      "+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca1e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
